# Talk To Youtuber

![gif](https://github.com/FardinAhsan146/TalkToYoutuber/blob/master/docs/talk_to_youtuber-Trim-Trimonline-video-cutter.com-ezgif.com-video-to-gif-converter.gif)

There's a youtuber whose videos I quite like named [japaneat](https://www.youtube.com/@japaneat). I'm going to visit Japan soon and I want to know what his reccomended (suchi, karage, ramen, udon, ...) restaurants are. However, its not like he has a nicely labelled and curated blog or Wiki. Everything he ever said is scrattered among YouTube shorts. 

There are API bindings out there that let you download Google autogenerated and owner uploaded transcripts. Why not just fetch all video data and chuck them into an LLM with RAG? 

For the LLM part I will just use openai embeddings and `gpt4-o`. 

This produce a CLI chatbot with the knowledge of a given youtuber and I can talk and ask questions. 

This project prioritizes simplicity and ease of development over all else. I should be able to finish it in 2-3 days. The choice of packages and architecture is primarily geared for that. If the project ever grows to something larger than I will use personally, it will require a significant refactor. I also won't using LangChain or LLaMaindex or any other LLM application framework. They are text processing interfaces for the most part and for a project of this size, it makes more sense to just code up the llm utils from the ground up. Not to mention that keeps the code less coupled (llm frameworks have utils for almost everything and it doesn't make sense to use only parts of them) and helps with portability. 

# Databases

So that you can come back and continue talk to your youtubers of choice! 

* [Sqlite3](https://sqlite.org/) : For storing app data. Anything more is overkill. 
* [ChromaDB](https://www.trychroma.com/) : A simple enough vector DB for the job. I really wanted to use a vector extension for sqlite but the main one is still in development and I don't want to handle changes to api continously. Chroma is simple, works on windows and gets the job done. Something like postgres with pgvector would have allowed me to get away with one database but its overkill for the volume of data. This combination of databases makes the project significantly more portable. 

# Youtube API 

You don't need credentials! 

I might probably have to refactor these to use the Youtube API in the future anyways to not have to depend on two different dependencies and make the code more extensible and legible. However, these are simple enough wrappers that don't need any credientials and abstract away the rough edges of Googles APIs which tend to be quite tedious to work with even for seemingly simple functionality.  

* [scrapetube](https://scrapetube.readthedocs.io/en/latest/) : Get youtube video data with Youtube API 
* [youtube-transcript-api](https://pypi.org/project/youtube-transcript-api/) : Get video transcript data with Youtube API 

----

# How to run. 

This project is designed to be maximally portable and easy to run. 

1. Install dependencies. You can use the `requirements.txt` this will install ALL of the dependencies. There will be a few additional ones that are a result of the tooling I used to develop, you might not need those. Else you can install the afforementioned YouTube API wrappers and chromaDB. 
2. Create a `.env` file in the `/llm` directory and populate it with your `OPENAI_API_KEY`. 
3. Run the `main.py` file. That's it really. 
4. The script will ask you for which youtubers you want to talk to. Just type in the youtubers name. Make sure its EXACTLY like it is in their channel (look at the channel URL). It will download their videos and once done, you can talk to GPT with their video transcripts semantically injected into the context of the chat. 
5. If you want to nuke the databases you can run the `clean_databases.ps1` script. Converting it to bash is trivial as well. Just delete the sqlite file and the chroma directory. You probably won't have to do this, unless your db gets currupted in some way. If you run into an error during the initial download (OpenAI timing out or Database connection closiing, rare but can happen), then nuke the databases. 

More instructions coming soon.

# Immediate attention 

* I need to add in a chunking mechanism. OpenAI embeddings take a max of 8k tokens. Currently I just truncate the transcripts to 30k characters (~6-7k tokens). This is naive and probably misses good context. 
* I need to make the chroma vector insert and the video transcript fetcher faster. Ideally I can make them multi threaded, but getting that to work with database transactions is going to be a bit of a hassle. 

# Future

* I want to refactor the code and make it database, api and interface agnostic for the most part. 
* I want to add in fuzz and regression testing.
* I want to add a feature where the user can pass in query params to the vector db in their message. This will allow for even better context fetching. For example, I might what to know japaneats favorite sushi restaurant in Tokyo. The match might not be a restaurant in tokyo. I can pass in a query param like `{"$includes":"tokyo"}` so I get context that has certain keywords. This will be a nice to have, but I will do this after I handle the major performance improvements.